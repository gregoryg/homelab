{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klEDKjIWiQte"
   },
   "source": [
    "# IoT Graph\n",
    "\n",
    "This demo is designed to demonstrate the some of the additional insights that you can gain by loading your existing streaming IoT data into a graph database.\n",
    "\n",
    "This demo will exist in multiple parts:\n",
    "\n",
    "1. Converting you existing data to be loaded into the graph\n",
    "2. Enriching your data with graph attributes\n",
    "3. Extracting additional insights from your data with graph queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NO6DsjWCQUTd"
   },
   "source": [
    "## The Goal\n",
    "\n",
    "The goal of this setup is to attempt to recognize how air and thermal energy flow throughout an indoor space. This indoor space is a 3rd floor apartment in Boston, MA consisting of two rooms, a bedroom and a workshop. Both rooms have a window, the one in the workshop faces East, and the one in the Bedroom faces South. \n",
    "\n",
    "In each window, there is a custom built sensor package. Each sensor records the ambient Temperature, Humidity, Pressure, and amount of Light at their location by their corresponding window. Additionally, the outdoor values for each of those readings are recorded as well.\n",
    "\n",
    "<img src=\"https://i.ibb.co/tLyYYMZ/Sensor-1.jpg\" width=\"44%\">\n",
    "<img src=\"https://i.ibb.co/gPRQKHm/Sensor-2.jpg\" width=\"40%\">\n",
    "\n",
    "The hope is that we will be able to predict the readings of these sensors given a weather forecast for any given day. Additionally, we will be exploring the relationship between the sensors and attempt to identify activities that are happening in the rooms based on the sensor readings. Finally, the real world isn't perfect, so we have some gaps in our data and it would be nice to be able to identify and fill in those values with predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AeIzsjYN9pA"
   },
   "source": [
    "# Part 1 - Understanding the Data and Building the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf-q-pst5KX1",
    "tags": []
   },
   "source": [
    "## Setting up the TigerGraph server\n",
    "\n",
    "Head over to [tgcloud.io](tgcloud.io) and create an account to begin creating you first TigerGraph solution.\n",
    "\n",
    "![](https://i.ibb.co/synTScQ/Screen-Shot-2021-08-24-at-5-23-52-PM.png)\n",
    "\n",
    "Once you have created your account and signed in, you can provision a solution by clicking the **Create Solution** button. \n",
    "\n",
    "![](https://i.ibb.co/vjwyp4T/Screen-Shot-2021-07-28-at-12-13-14-AM.png)\n",
    "\n",
    "Next, select **Blank** from the Starter Kits menu. We'll be setting up our own graph here. Click the next button at the bottom to continue to the **Instance Settings**.\n",
    "\n",
    "![](https://i.ibb.co/MSkwPBk/Screen-Shot-2021-07-28-at-12-21-10-AM.png)\n",
    "\n",
    "We'll use a free tier instance for this demo, you can leave the rest of these settings default. Click the next button at the bottom to move on to setting up the **Solution Settings**.\n",
    "\n",
    "![](https://i.ibb.co/kGXFjvD/Screen-Shot-2021-07-28-at-12-24-07-AM.png)\n",
    "\n",
    "The last things that we'll need to customize are the instance settings. Here's what each one does:\n",
    "- **Solution Name** - the name you will see this solution referred to on the **My Solutions** page\n",
    "- **Solution Tag** - single word tags that can be used to filter the solution in the **My Solutions** page\n",
    "- **Initial Password** - the password used to log into this TigerGraph Solution - default: `tigergraph`\n",
    "- **Subdomain** - the subdomain where your TigerGraph Solution will live - can only conatin lower case letters, numbers, and hyphens **(Set this to something you will remember as you will use it to access your solution)**\n",
    "- **Description** - a description of the solution\n",
    "\n",
    "\n",
    "#### For this demo, you can use:\n",
    "- **Name** - `IoT Graph`\n",
    "- **Tag** - `iot`\n",
    "- **Password** - `tigergrpah`\n",
    "- **Subdomain** - `iot-graph`\n",
    "- **Description** - you can leave blank\n",
    "\n",
    "![](https://i.ibb.co/gtCmXcm/Screen-Shot-2021-07-28-at-12-27-19-AM.png)\n",
    "\n",
    "Finally, review your settings on the **Confirmation Page** and click submit if they look good.\n",
    "\n",
    "![](https://i.ibb.co/hyN2Dcv/Screen-Shot-2021-07-28-at-12-31-12-AM.png)\n",
    "\n",
    "It will take about 5 minutes for your solution to provision and spin up for the first time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWaFas1ZTihS"
   },
   "source": [
    "## The Data\n",
    "\n",
    "IoT data can take a variety of forms. It can be streaming data in any varitey of formats: websockets, kafka streams, data dumps and chron jobs, there's really no limit to how the real world can structure \"realtime\" IoT data.\n",
    "\n",
    "For this example, I wrote a library to allow ESP32 microcontrollers to post directly to Tigergraph. The pre-alpha version of this library is available here: https://github.com/DanBarkus/microTigerGraph Additionally, this could be set up using our Node Red style interface: [TigerFlow](https://github.com/TigerGraph-DevLabs/TigerFlow)\n",
    "\n",
    "![](https://i.ibb.co/0CkZFgJ/Screen-Shot-2021-09-23-at-11-46-45-AM.png)\n",
    "\n",
    "This basic diagram can be split in half for easier understanding, but demsonstrates the basic method that we will want store our data in. \n",
    "\n",
    "On the left half, we have information describing the origins of any given `Reading`. A `Device` is the physical sensor module that recorded a `Reading`. We have two physical devices, **Window** and **Workshop** (the sensors) and one virtual device **Outside**.\n",
    "\n",
    "Each device has four different `Reading_Type`s that it can capture: **Temperature**, **Humidity**, **Pressure**, and **Light Intensity**. With this structure, we can dynamically select any type of reading from any particular device.\n",
    "\n",
    "On the right side is our information about when the reading was captured. This will come in handy when we're looing to corelate readings from multiple sensors and attempt to predict missing or upcoming data.\n",
    "\n",
    "`Day` is a datetime representing the Day of the year that the `Reading` was captured on. `Hour` is an INT representing the hour of the day when a `Reading` was captured. We could go down to `Minute` here, but the frequency of our data doesn't necessitate storage more granular than an hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rug1VO_1N6Xa"
   },
   "source": [
    "### Exploring the Data\n",
    "Let's take a look at what this data actually looks like.\n",
    "Because the data for this demo was generated by streaming devices, there's no easy way for me to give you access to that streaming data. Instead I've included about a 3 week export of a portion of the sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEOuR0SWN5_x",
    "outputId": "1d30c80a-f49b-466e-9016-df4de55ead9d"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/DanBarkus/IoT-Dashboard.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kuc5JyilPVve"
   },
   "source": [
    "That data exists in 3 files, one for each of our sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VA2P_M9yPZuW",
    "outputId": "1f80cf3d-8743-4482-88ff-1cdff4dfbb5a"
   },
   "outputs": [],
   "source": [
    "!ls IoT-Dashboard/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVTkG3kMPjGR"
   },
   "source": [
    "Those files are structured like this:\n",
    "\n",
    "|@device|@rdgType|value|type|captured_at|\n",
    "|-------|--------|-----|----|-----------|\n",
    "|Device Name (corresponds to `Device` vertex id)|Reading Type (corresponds to `Reading_Type` vertex id)|Value of Reading|Type of sensor that produced the reading|`DATETIME` that the reading was captured at|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XezoRq4PO-5-",
    "outputId": "2504487e-e7ef-440f-cc85-9b40feef0d71"
   },
   "outputs": [],
   "source": [
    "!head IoT-Dashboard/data/Window.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cis0xrbTRIjg"
   },
   "source": [
    "A keen observer may notice that we're missing a couple things from the schema picture shown earlier. Mainly, there's no field for just `Date` or `Hour`. That's okay because we'll be extracting those from the **captured_at** value during data loading.\n",
    "\n",
    "You may also notice that there are no unique identifers for our rows of data (the first column has numbers, but they are duplicated across our three data files an were purely a product of the data extraction process). We will also be generating a unique identifier for each reading based on a combination of its `Device`, `Reading_Type` and `captured_at` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd2zaC9jhskK"
   },
   "source": [
    "## Connecting from Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRXMj8lATmTL"
   },
   "source": [
    "### Python Installs and Imports for **TigerGraph**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alx1oJEGJVc1"
   },
   "source": [
    "pyTigerGraph will be the main tool that we'll be using to interface with the graph from python. You can learn more about pyTigerGraph with our [intro video](https://www.youtube.com/watch?v=2BcC3C-qfX4&t=1s), or by reading the [docs](https://pytigergraph.github.io/pyTigerGraph/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYJzHGeMkFKb"
   },
   "outputs": [],
   "source": [
    "# !pip install pyTigerGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TaQCHEPmPwc"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyTigerGraph as tg\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_mIiSC_0pl8"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "def pprint(input):\n",
    "  print(json.dumps(input, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Vfl-U_eTxBu"
   },
   "source": [
    "### Establishing a Connection\n",
    "\n",
    "Change the values below to so that `hostName` matches your **Subdomain** and the `password` matches what you set if you've changed it.\n",
    "\n",
    "This will establish the inital connection to our TigerGraph solution. There is currently no graph or schema in the solution, so that will need to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yfcnk4nuucGn",
    "outputId": "9591cf92-7c91-4ea8-c162-838624574bf6"
   },
   "outputs": [],
   "source": [
    "# Connection parameters\n",
    "# hostName = \"https://iot-2.i.tgcloud.io\"\n",
    "hostName = \"http://homelab-k3s.172.16.17.16.nip.io\"\n",
    "userName = \"tigergraph\"\n",
    "password = \"Tigergraph\"\n",
    "\n",
    "conn = tg.TigerGraphConnection(host=hostName, username=userName, password=password)\n",
    "\n",
    "print(\"Connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_LjuuEbUQyp"
   },
   "source": [
    "## Understanding the Schema\n",
    "\n",
    "The core of any graph solution is a **Schema**. The **Schema** defines what each type of vertex is and how it relates to other types of vertices via edges.\n",
    "\n",
    "Both Vertices and Edges can have attributes which can further describe them.\n",
    "\n",
    "Think of each **Vertex Type** as a **Table** in a relational database. **Attributes** of that Vertex Type are your **Columns** from that Table and each **Individual Vertex** is analagous to a **Row** from your Table. **Edges** represent **Joins** between tables. As part of the Schema, Edges are computed during data load and sotred in memory rather than being computed during query time.\n",
    "\n",
    "This is an absolute bare-bones manner of implementing a graph schema, but since we're working on converting our existing relational data to graph data, it makes sense to start with something familiar and build off of that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXR7D_8fYenv"
   },
   "source": [
    "This is the schema that we'll be starting with:\n",
    "![](https://i.ibb.co/0CkZFgJ/Screen-Shot-2021-09-23-at-11-46-45-AM.png)\n",
    "\n",
    "You'll notice that our data files already contain:\n",
    "- `Reading` - with value and addtional information\n",
    "- `Device` - that created the Reading\n",
    "- `Reading Type` - that the Reading represents\n",
    "- Full DATETIME that the reading was captured at\n",
    "\n",
    "That means that there's no explicit Column in our Data for `Day` or `Hour`. That's okay because they're both contained in the `captured_at` value of each `Reading`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swlgHRkVZ7jy"
   },
   "source": [
    "### The Story Behind `Day` and `Hour`\n",
    "\n",
    "`Day` and `Hour` might not make sense at first as Vertex Types. Why not just store the full datetime attached to each `Reading`?\n",
    "\n",
    "The reason comes down to our data. Each of the indoor sensors captures a new batch of readings about every 2 minutes. The Outdoor data is fetched from a weather API and has 15 minute to 1 hour intervals seemingly at random. \n",
    "\n",
    "If we're looking to correlate our Outdoor readings with our Indoor readings then we can't compare them 1:1 due to the difference in frequency (max 1 hour vs 2 minutes).\n",
    "\n",
    "The two options are:\n",
    "- Interpolate the Outdoor readings to the same frequency as the Indoor readings\n",
    "  - Pros: High frequency data from both sources\n",
    "  - Cons: Assumed values of interpolated readings can yield inaccurate results\n",
    "- Round Indoor (and Outdoor) readings to the same low frequency that contains at least one reading per sensor, per period\n",
    "  - Pros: More accurate as readings aren't assumed\n",
    "  - Cons: Low frequency of data\n",
    "\n",
    "For this demo, I chose the second option, Round to a common value. This is why `Hour` exists. When comparing readings from Outdoor and Indoor, the query can simply SELECT any `Reading` vertices that are connected input `Day`, `Hour`, and `Device` vertices.\n",
    "\n",
    "`Hour` and `Day` essentially act as an easily accessable way for us to query a specific time period without having to check the date of every `Reading` in the Graph. **VertexID** exists entirely in **RAM** and **Edges** act as **Pointers** between memory addresses. **Attributes** are stored on **Disk**, so accessing them incurs a performance penalty. **Without** `Hour` and `Day`, selecting all `Readings` from an hour long time period on a specific day would involve selecting every `Reading` in the graph and checking it's captured_at attribute on disk to see if it is within the time range. **With** `Hour` and `Day`, we use the **VertexID** (in RAM) of the input `Day` and `Hour` to traverse Edges (also in RAM) to any `Reading` vertices connected to both the input `Hour` and `Day`. With this method, the entire query operates on data stored in RAM and only touches the verties that are actually returned from the query.\n",
    "\n",
    "At the scale of the data in this demo, the performance impact of these methods is negligable (<3ms), but real-world scale with hundreds of millions+ readings will benefit from foresight when building the schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yV64JvnvL_49"
   },
   "source": [
    "## Loading the Schema\n",
    "\n",
    "We'll be creating the schema through a series of **GSQL** queries that we'll execute through pyTigerGraph.\n",
    "\n",
    "The **schema** describes **each type of node in the graph and how it relates to other types of nodes via edges**. You can learn more about the GSQL commands for schema definition [in our docs](https://docs.tigergraph.com/start/gsql-101/define-a-schema). But in a nutshell it looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTlWbO6ldKHG"
   },
   "source": [
    "### Create Vertices\n",
    "\n",
    "`CREATE VERTEX <VERTEX_TYPE_NAME>(PRIMARY_ID <PRIMARY_ID_NAME> <PRIMARY_ID_TYPE>, <ATTRIBUTE_NAME> <ATTRIBUTE_TYPE>, ...)`\n",
    "\n",
    "- `CREATE` - We're adding something to the solution\n",
    "- `VERTEX` - It's a vertex type that's being added\n",
    "- `<VERTEX_TYPE_NAME>` - The name you want to give to your vertex type\n",
    "- `PRIMARY_ID` - Specifies that the next input will be the **name of the primary_id**\n",
    "- `<PRIMARY_ID_NAME>` - The name of the primary_id field\n",
    "- `<PRIMARY_ID_TYPE>` - The variable type of the primary_id\n",
    "- `<ATTRIBUTE_NAME>` - The name of an attribute of the vertex - **Attributes are optional and each vertex can contain more than one**\n",
    "- `<ATTRIBUTE_TYPE>` - The variable type of the attribute\n",
    "\n",
    "Addtionally, we want to specify that the `primary_id` of the vertex should also be duplicated as an attribute so that we can reference it from queries. That is done by adding:\n",
    "`WITH primary_id_as_attribute=\"true\"`\n",
    "to the end of the VERTEX decleration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OhS7fYG9GTf0",
    "outputId": "06f52b75-f756-4c69-af05-b388210e059f"
   },
   "outputs": [],
   "source": [
    "conn.gsql('''\n",
    "drop graph IoTDashboard\n",
    "create graph IoTDashboard()\n",
    "use graph IoTDashboard\n",
    "drop job iot_schema\n",
    "create schema_change job iot_schema for graph IoTDashboard {\n",
    "ADD VERTEX Reading(PRIMARY_ID id STRING, value FLOAT, type STRING, captured_at DATETIME) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
    "ADD VERTEX Device(PRIMARY_ID id STRING, type STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
    "ADD VERTEX Reading_Type(PRIMARY_ID id STRING, unit STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
    "ADD VERTEX Day(PRIMARY_ID date STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
    "ADD VERTEX Hour(PRIMARY_ID hour INT) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
    "add DIRECTED EDGE has_reading(FROM Device, TO Reading) WITH REVERSE_EDGE=\"reverse_has_reading\";\n",
    "add DIRECTED EDGE on_day(FROM Reading, TO Day) WITH REVERSE_EDGE=\"reverse_on_day\";\n",
    "add DIRECTED EDGE on_hour(FROM Reading, TO Hour) WITH REVERSE_EDGE=\"reverse_on_hour\";\n",
    "add DIRECTED EDGE of_type(FROM Reading, TO Reading_Type) WITH REVERSE_EDGE=\"reverse_of_type\";\n",
    "}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NukaZT_sdeFc"
   },
   "source": [
    "### Create Edges\n",
    "\n",
    "`CREATE DIRECTED|UNDIRECTED EDGE <EDGE_TYPE_NAME>(FROM <SOURCE_VERTEX_TYPE>, TO <DESTINATION_VERTEX_TYPE>, <ATTRIBUTE_NAME> <ATTRIBUTE_TYPE>, ...)`\n",
    "\n",
    "- `CREATE` - We're adding something to the solution\n",
    "- `DIRECTED|UNDIRECTED` - Specify if the edge is Directed or Undirected\n",
    "- `EDGE` - It's an edge type that's being added\n",
    "- `<EDGE_TYPE_NAME>` - The name you want to give to your edge type\n",
    "- `FROM` - Specifies that the next input will be the **source vertex type**\n",
    "- `<SOURCE_VERTEX_TYPE>` - The vertex type of the source of the edge\n",
    "- `TO` - Specifies that the next input will be the **destination vertex type**\n",
    "- `<DESTINATION_VERTEX_TYPE>` - The vertex type of the destination of the edge\n",
    "- `<ATTRIBUTE_NAME>` - The name of an attribute of the edge - **Attributes are optional and each edge can contain more than one**\n",
    "- `<ATTRIBUTE_TYPE>` - The variable type of the attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "OJfWAMDcG_fG",
    "outputId": "9e4e4666-36d1-4b0d-cea2-25a94344e6df"
   },
   "outputs": [],
   "source": [
    "# conn.gsql('''\n",
    "# CREATE DIRECTED EDGE has_reading(FROM Device, TO Reading) WITH REVERSE_EDGE=\"reverse_has_reading\"\n",
    "# CREATE DIRECTED EDGE on_day(FROM Reading, TO Day) WITH REVERSE_EDGE=\"reverse_on_day\"\n",
    "# CREATE DIRECTED EDGE on_hour(FROM Reading, TO Hour) WITH REVERSE_EDGE=\"reverse_on_hour\"\n",
    "# CREATE DIRECTED EDGE of_type(FROM Reading, TO Reading_Type) WITH REVERSE_EDGE=\"reverse_of_type\"\n",
    "# ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hWA08Cfuqls"
   },
   "source": [
    "## Create Graph\n",
    "\n",
    "The schema that we just created exists in the **Global** sense. We can have more than one **Graph** per **Solution**, so a **Global** schema allows us to re-use parts or all of that schema across multiple graphs.\n",
    "\n",
    "We're not going to need to do anything fancy like that for this demo, it's just important to know that any **Graphs** can contain none or any number of elements from the **Global** schema and can even contain elements that are unique to that **Graph's** schema.\n",
    "\n",
    "The command to create the graph is another GSQL block following this pattern:\n",
    "\n",
    "`CREATE GRAPH <GRAPH_NAME>(<VERTEX_TYPE>|<EDGE_TYPE>, ...)`\n",
    "\n",
    "- `CREATE` - We're adding something to the solution\n",
    "- `GRAPH` - It's an graph that's being added\n",
    "- `<GRAPH_NAME>` - The name you want to give to your graph\n",
    "- `<VERTEX_TYPE>|<EDGE_TYPE>` - The name of a **Vertex Type** or **Edge Type**  - This can be repeated for as many vertex types or edge type you want to include in your graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "HVxp_svsHf99",
    "outputId": "0a9c2a6b-20d4-4379-cb4c-8668f5a75c18"
   },
   "outputs": [],
   "source": [
    "# conn.gsql('''\n",
    "# CREATE GRAPH IoTDashboard(Reading, Device, Reading_Type, Day, Hour, has_reading, on_day, on_hour, of_type)\n",
    "# ''')\n",
    "conn.gsql('''\n",
    "use graph IoTDashboard\n",
    "run schema_change job iot_schema\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X44JFtpQi0kp"
   },
   "source": [
    "### Re-connecting to the Graph\n",
    "\n",
    "Now that the graph is created, we need to update our pyTigerGraph connection to point specifically to our graph. This will allow us to create a **Secret**, then use that **Secret** to get a **Token** which will be used for secure authentication to that specific graph in our **Solution**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UsD6fxBWuu8l",
    "outputId": "c7e5d923-337d-4d41-907a-3fe188ab8e72"
   },
   "outputs": [],
   "source": [
    "graphName = \"IoTDashboard\"\n",
    "conn.graphname = graphName\n",
    "# secret = conn.createSecret()\n",
    "# token = conn.getToken(secret, setToken=True)\n",
    "token = \"cdepgpk5oebgs6gsqbvijccb3lngavbg\"\n",
    "conn.apiToken = token\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Py9Uuep5xaMk"
   },
   "source": [
    "## Loading Jobs\n",
    "\n",
    "A **Loading Job** defines how fields from our input files map to the primary_id and attributes of vertices and source and destination vertices and attributes of edges.\n",
    "\n",
    "To help visualize what's going on here, let's clone our data so we know what it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzz6H2Z9m8yR"
   },
   "source": [
    "### Anatomy of a Loading Job\n",
    "\n",
    "Looking at the loading job below, you'll see that we don't refer to the column names of our data by their headers, but rather by their column number. The chart below shows how that compares to the header from our alergies file above.\n",
    "\n",
    "|Column Number|\\$0|\\$1|\\$2|\\$3|\\$4|\\$5|\\$6|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|Column Name|ID|START|STOP|PATIENT|ENCOUNTER|CODE|DESCRIPTION|\n",
    "\n",
    "Go ahead and creat this loading job and I'll break down exactly what's going on here afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z1rG89Q2v4W7",
    "outputId": "07aab394-beeb-4358-d9f6-02cfbdc5aaba"
   },
   "outputs": [],
   "source": [
    "!head IoT-Dashboard/data/Outside.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mMfL0sQZvDz2",
    "outputId": "9b4fb863-69cb-4b02-91b0-ea43c4790a92"
   },
   "outputs": [],
   "source": [
    "conn.gsql('''\n",
    "CREATE LOADING JOB load_sensor FOR GRAPH IoTDashboard {\n",
    "      DEFINE FILENAME MyDataSource;\n",
    "      LOAD MyDataSource TO VERTEX Reading VALUES(gsql_concat($1,$2,$5), $3, $2, $5) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
    "      LOAD MyDataSource TO VERTEX Device VALUES($1, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
    "      LOAD MyDataSource TO VERTEX Reading_Type VALUES($2, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
    "      LOAD MyDataSource TO EDGE of_type VALUES(gsql_concat($1,$2,$5), $2) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
    "      LOAD MyDataSource TO EDGE has_reading VALUES($1, gsql_concat($1,$2,$5)) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
    "    }\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1jvOF_qpm6j"
   },
   "source": [
    "#### Loading Job Breakdown\n",
    "\n",
    "`CREATE LOADING JOB <LOADING_JOB_NAME> FOR GRAPH <GRAPH_NAME> {`\n",
    "\n",
    "- `CREATE` - We're adding something to the solution\n",
    "- `LOADING JOB` - It's an loading job that's being added\n",
    "- `<LOADING_JOB_NAME>` - The name you want to give to your loading job\n",
    "- `FOR GRAPH` - The next input will specify which graph the job is for\n",
    "- `<GRAPH_NAME>` - The name of the graph that the loading job is for\n",
    "\n",
    "```\n",
    "DEFINE FILENAME <FILE_VARIABLE_NAME>;\n",
    "LOAD <FILE_VARIABLE_NAME>\n",
    "  TO VERTEX|EDGE <VERTEX_TYPE>|<EDGE_TYPE> VALUES(<COLUMN_NUMBER>, ...)\n",
    "```\n",
    "\n",
    "- `DEFINE` - Defining a Variable\n",
    "- `FILENAME` - The type of variable being defined\n",
    "- `<FILE_VARIABLE_NAME>` - The name of the variable that will represent our input file\n",
    "- `LOAD` - Specify that the next input is the file that we will be loading\n",
    "- `<FILE_VARIABLE_NAME>` - The file variable that we are loading\n",
    "- `TO` - The next input is a vertex type or edge type that the loading job will apply to\n",
    "- `VERTEX|EDGE` - Specify if the Job is loading to a Vertex or Edge\n",
    "- `<VERTEX_TYPE>|<EDGE_TYPE>` - The name of the vertex type or edge type being loaded into\n",
    "- `VALUES` - The next input contains the Column Numbers in order of the fields they represent\n",
    "\n",
    "**Values Layout**\n",
    "\n",
    "**Vertex**\n",
    "`VALUES(PRIMARY_ID, ATTRIBUTE_1, ATTRIBUTE_2, ...)`\n",
    "\n",
    "**Edge**\n",
    "`VALUES(SOURCE_ID, DESTINATION_ID, ATTRIBUTE_1, ATTRIBUTE_2, ...)`\n",
    "\n",
    "Additionally we specify any additional options for the loading job after a `USING` statement. For a full list of options check the [Loading Job Documentation](https://docs.tigergraph.com/dev/gsql-ref/ddl-and-loading/creating-a-loading-job#create-loading-job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtBl3BrTwpQn"
   },
   "source": [
    "## Loading Data\n",
    "\n",
    "Now that the loading jobs have been created, we can begin actually loading in data. We'll be stepping away from the GSQL heavy work that we've been using so far and switch back to more python oriented code for loading.\n",
    "\n",
    "First, we load the data file into a variable.\n",
    "\n",
    "`uploadFile()` requires 3 inputs:\n",
    "- `filePath` - The actual data file to load\n",
    "- `fileTag` - This is the name of the variable that the file will correspond to in the loading job. If you remember, we're using `f1` as our FILENAME variable in the loading jobs.\n",
    "- `jobName` - The name of the corresponding loading job to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0t5FohTWxSZq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Run each of our 3 data files through the Loading Job\n",
    "directory = r'IoT-Dashboard/data'\n",
    "for dataFile in os.scandir(directory):\n",
    "  if dataFile.path.endswith(\".csv\"):\n",
    "    results = conn.uploadFile(dataFile, fileTag='MyDataSource', jobName='load_sensor')\n",
    "    print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRvuuSgv3QJ1"
   },
   "source": [
    "## Add Hours and Days\n",
    "\n",
    "Remember those `Hour` and `Day` vertices that we didn't end up loading in with the rest of our data? Well now it's time to create them. \n",
    "\n",
    "We're doing this from a query rather than when loading the data right now. In a real world use-case, you would want these edges to be generated when the readings are added to the graph. Because we're going through the process of upgrading our existing solution, we have data that we need to generate these edges for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "IANplMXM2EmE",
    "outputId": "9c1b8b91-7412-41ce-dcdf-1969d9b77a63"
   },
   "outputs": [],
   "source": [
    "conn.gsql(\n",
    "    '''\n",
    "    USE GRAPH IoTDashboard\n",
    "    CREATE QUERY addHoursAndDays() FOR GRAPH IoTDashboard { \n",
    "      MinAccum<INT> @currentHour;\n",
    "      MaxAccum<STRING> @currentDay;\n",
    "      readings = {Reading.*};\n",
    "      \n",
    "      noHour = SELECT r FROM readings:r\n",
    "        WHERE\n",
    "          r.OUTDEGREE(\"on_hour\") == 0\n",
    "        ACCUM\n",
    "          r.@currentHour = HOUR(r.captured_at)\n",
    "        POST-ACCUM\n",
    "          INSERT INTO on_hour (FROM, TO)VALUES (r.id, r.@currentHour);\n",
    "      \n",
    "      noDay = SELECT r FROM readings:r\n",
    "        WHERE\n",
    "          r.OUTDEGREE(\"on_day\") == 0\n",
    "        ACCUM\n",
    "          r.@currentDay += datetime_format(r.captured_at, \"%Y-%m-%d\")\n",
    "        POST-ACCUM\n",
    "          INSERT INTO on_day (FROM, TO)VALUES (r.id, r.@currentDay);\n",
    "      \n",
    "      PRINT noDay;\n",
    "    }\n",
    "    INSTALL QUERY addHoursAndDays\n",
    "    '''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFsZ_Ef__Pau"
   },
   "outputs": [],
   "source": [
    "conn.runInstalledQuery('addHoursAndDays', params={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNaRrCmwy1Y6"
   },
   "source": [
    "# Part 1.5 - Building the Dashboard\n",
    "\n",
    "The graph has been set up and the data has been loaded. We could start poking away at the data in Graph Studio. Or... hear me out, we could build out a cool dashboard to show off the data.\n",
    "\n",
    "I'm glad you picked the dashboard, I did too.\n",
    "\n",
    "We'll use [Plotly Dash](https://dash.plotly.com/introduction) to build out the interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9ChninV1WJ3"
   },
   "source": [
    "## Installing Dash\n",
    "\n",
    "Let's get the installs and imports out of the way first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lX80090PynYy"
   },
   "outputs": [],
   "source": [
    "!pip install -q jupyter-dash\n",
    "!pip install -q plotly\n",
    "!pip install -q dash-bootstrap-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXwTiLUTyhOM"
   },
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "import datetime\n",
    "import math\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQjp4N5B3hAi"
   },
   "source": [
    "## Creating Queries to Fetch Data from the Graph\n",
    "\n",
    "I know we're supposed to be working on the dashboard, but the dashboard isn't much use if it can't get to our data. Further, we need to know what that data coming back from our queries looks like before we can start writing code to display it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiuC9SR3Seip"
   },
   "source": [
    "### Get all Readings for a Sensor\n",
    "\n",
    "At the core of our dashboard, we need to display our data. We'll have a couple charts that we'll be displaying and they'll each have a dropdown to select which information will be displayed.\n",
    "\n",
    "We can either fetch the relevant information each time that dropdown is changed, or we can fetch all the data at once when the page loads and just filter on the front end from there. Will be doing the later option as it reduces the number of total calls our page will need to make and reduces the overall time spent loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uo6OT5JRRv91",
    "outputId": "c3859156-f8c5-4f6e-e494-1bafbe902ba2"
   },
   "outputs": [],
   "source": [
    "conn.gsql(\n",
    "    '''\n",
    "    USE GRAPH IoTDashboard\n",
    "    CREATE QUERY getReadingsForSensor(VERTEX<Device> inDevice) FOR GRAPH IoTDashboard SYNTAX v2 {\n",
    "      STRING visVar;\n",
    "      device = {inDevice};\n",
    "      \n",
    "      IF inDevice.id == \"Outside\" \n",
    "        THEN visVar = \"CLOUD\";\n",
    "      ELSE\n",
    "        visVar = \"LUX\";\n",
    "      END;\n",
    "      \n",
    "      temperatures = SELECT t FROM device - () - Reading:t - (of_type>) - Reading_Type:rt WHERE\n",
    "        rt.id == \"TEMPERATURE\";\n",
    "      \n",
    "      PRINT temperatures;\n",
    "      \n",
    "      humidities = SELECT t FROM device - () - Reading:t - (of_type>) - Reading_Type:rt WHERE\n",
    "        rt.id == \"HUMIDITY\";\n",
    "      \n",
    "      PRINT humidities;\n",
    "      \n",
    "      pressures = SELECT t FROM device - () - Reading:t - (of_type>) - Reading_Type:rt WHERE\n",
    "        rt.id == \"PRESSURE\";\n",
    "      \n",
    "      PRINT pressures;\n",
    "      \n",
    "      lux = SELECT t FROM device - () - Reading:t - (of_type>) - Reading_Type:rt WHERE\n",
    "        rt.id == visVar;\n",
    "      \n",
    "      PRINT lux;\n",
    "    }\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "efvO_C5SAfnh",
    "outputId": "e8754e6c-1b74-4156-da82-cc6198bc7027"
   },
   "outputs": [],
   "source": [
    "conn.gsql('''\n",
    "INSTALL QUERY getReadingsForSensor\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBFOIoSYShbj"
   },
   "source": [
    "### Get NEW Readings for a Sensor\n",
    "\n",
    "This is realtime data (or at least it is on the original graph...) so the dashboard needs to be able to fetch updated data if its available.\n",
    "\n",
    "This query will only return the most recent readings for an input device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "OsJh-taPSkWO",
    "outputId": "c6c292dc-e81d-4ee0-fe46-ab9059a368b6"
   },
   "outputs": [],
   "source": [
    "conn.gsql(\n",
    "    '''\n",
    "    USE GRAPH IoTDashboard\n",
    "    CREATE QUERY getMostRecentForSensor(VERTEX<Device> inDevice) FOR GRAPH IoTDashboard SYNTAX v2{ \n",
    "      STRING visVar;\n",
    "      MapAccum<STRING, FLOAT> @@mostRecent;\n",
    "      SetAccum<VERTEX> @@tempReadings;\n",
    "      SetAccum<VERTEX> @@humidReadings;\n",
    "      SetAccum<VERTEX> @@pressureReadings;\n",
    "      SetAccum<VERTEX> @@luxReadings;\n",
    "      MaxAccum<DATETIME> @@recentTime;\n",
    "      \n",
    "      dev = {inDevice};\n",
    "      \n",
    "      IF inDevice.id == \"Outside\" \n",
    "        THEN visVar = \"CLOUD\";\n",
    "      ELSE\n",
    "        visVar = \"LUX\";\n",
    "      END;\n",
    "      \n",
    "      \n",
    "      temperature = SELECT r FROM dev:l - (:e) - Reading:r - () - Reading_Type:t WHERE t.id == \"TEMPERATURE\"\n",
    "          ACCUM\n",
    "            @@recentTime += r.captured_at\n",
    "          POST-ACCUM\n",
    "            IF r.captured_at == @@recentTime THEN\n",
    "              @@mostRecent += (\"TEMPERATURE\" -> r.value),\n",
    "              @@tempReadings += r\n",
    "            END;\n",
    "      \n",
    "      @@recentTime = to_datetime(\"0\");\n",
    "      \n",
    "      humidity = SELECT r FROM dev:l - (:e) - Reading:r - () - Reading_Type:t WHERE t.id == \"HUMIDITY\"\n",
    "          ACCUM\n",
    "            @@recentTime += r.captured_at\n",
    "          POST-ACCUM\n",
    "            IF r.captured_at == @@recentTime THEN\n",
    "              @@mostRecent += (\"HUMIDITY\" -> r.value),\n",
    "              @@humidReadings += r\n",
    "            END;\n",
    "      \n",
    "      @@recentTime = to_datetime(\"0\");\n",
    "      \n",
    "      pressure = SELECT r FROM dev:l - (:e) - Reading:r - () - Reading_Type:t WHERE t.id == \"PRESSURE\"\n",
    "          ACCUM\n",
    "            @@recentTime += r.captured_at\n",
    "          POST-ACCUM\n",
    "            IF r.captured_at == @@recentTime THEN\n",
    "              @@mostRecent += (\"PRESSURE\" -> r.value),\n",
    "              @@pressureReadings += r\n",
    "            END;\n",
    "      \n",
    "      @@recentTime = to_datetime(\"0\");\n",
    "      \n",
    "      lux = SELECT r FROM dev:l - (:e) - Reading:r - () - Reading_Type:t WHERE t.id == visVar\n",
    "          ACCUM\n",
    "            @@recentTime += r.captured_at\n",
    "          POST-ACCUM\n",
    "            IF r.captured_at == @@recentTime THEN\n",
    "              @@mostRecent += (\"LUX\" -> r.value),\n",
    "              @@luxReadings += r\n",
    "            END;\n",
    "      \n",
    "      temperatures = {@@tempReadings};\n",
    "      humidities = {@@humidReadings};\n",
    "      pressures = {@@pressureReadings};\n",
    "      lux = {@@luxReadings};\n",
    "\n",
    "      print temperatures;\n",
    "      print humidities;\n",
    "      print pressures;\n",
    "      print lux;\n",
    "      print @@mostRecent;\n",
    "      print @@recentTime;\n",
    "    }\n",
    "    INSTALL QUERY getMostRecentForSensor\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiJtL_m0FvgZ"
   },
   "source": [
    "## The Dashboard for Real this Time\n",
    "\n",
    "Now it's time to actually build out the Dash dashboard and related functions. We'll start again with the functions needed to fetch our data. We wrote the query, now we need the python function that will actually call that query and process the results into the format we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS9MIBmwXFnq"
   },
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMwRyg-uJI0V"
   },
   "outputs": [],
   "source": [
    "sensors = [\"Window\", \"Workshop\", \"Outside\"]\n",
    "readingTypes = [\"Temperature\", \"Humidity\", \"Pressure\", \"Lux\"]\n",
    "currentSensor = \"\"\n",
    "currentType = \"\"\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pO-zJDLUvO6"
   },
   "source": [
    "### Data Retrieval and Formatting from TigerGraph\n",
    "\n",
    "This function serves as the backbone for retreiving reading data from TigerGraph. There's two ways that we want to get readings data, and we want them both to return in the same format.\n",
    "\n",
    "1. We first want ALL readings, this is on page load and is the initial data fetch.\n",
    "2. After we have all the data, we need to check periodically to see if there's new data and only fetch the new data (no sense wasting resources processing the full data again).\n",
    "\n",
    "This function looks like a lot of code, but it's actually pretty simple (just done 4x for each reading type)\n",
    "\n",
    "Here's the basic breakdown:\n",
    "\n",
    "1. Fetch data from TigerGraph\n",
    "  - `conn.runInstalledQuery(\"getReadingsForSensor\")` - query returns an list of 4 vertex sets, one for each reading type containing all readings of that type for the input sensor\n",
    "2. Convert each vertex set to a Pandas dataframe\n",
    "  - `conn.vertexSetToDataFrame()`\n",
    "3. Convert `captured_at` from a string to a python datetime\n",
    "4. Order by `captured_at`\n",
    "5. Set the `type` based on the reading type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atLY0qF3L9Xy"
   },
   "outputs": [],
   "source": [
    "# Run the Query and return a dataframe for each `Reading_Type` returned\n",
    "def pickData(sensor, firstTime=False):\n",
    "  if firstTime:\n",
    "    res = conn.runInstalledQuery(\"getReadingsForSensor\", params={\"inDevice\": sensor})\n",
    "  else:\n",
    "    res = conn.runInstalledQuery(\"getMostRecentForSensor\", params={\"inDevice\": sensor})\n",
    "  temps = res[0][\"temperatures\"]\n",
    "  humids = res[1][\"humidities\"]\n",
    "  pressures = res[2][\"pressures\"]\n",
    "  lux = res[3][\"lux\"]\n",
    "\n",
    "  # convert the vertex sets from the query in to Pandas Dataframes\n",
    "  dfTemps = conn.vertexSetToDataFrame(temps)\n",
    "  dfHumids = conn.vertexSetToDataFrame(humids)\n",
    "  dfPressures = conn.vertexSetToDataFrame(pressures)\n",
    "  dfLux = conn.vertexSetToDataFrame(lux)\n",
    "\n",
    "  # Convert captured_at to Datetime\n",
    "  dfTemps['captured_at'] = pd.to_datetime(dfTemps['captured_at'])\n",
    "  # Rename the type (it was incorrectly set on the sensors)\n",
    "  dfTemps[\"type\"] = dfTemps[\"id\"].str.extract(r'([A-Z]{2,})')\n",
    "  # Sort by date\n",
    "  dfTemps= dfTemps.sort_values(\"captured_at\")\n",
    "\n",
    "  dfHumids['captured_at'] = pd.to_datetime(dfHumids['captured_at'])\n",
    "  dfHumids[\"type\"] = dfHumids[\"id\"].str.extract(r'([A-Z]{2,})')\n",
    "  dfHumids= dfHumids.sort_values(\"captured_at\")\n",
    "\n",
    "  dfPressures['captured_at'] = pd.to_datetime(dfPressures['captured_at'])\n",
    "  dfPressures[\"type\"] = dfPressures[\"id\"].str.extract(r'([A-Z]{2,})')\n",
    "  dfPressures= dfPressures.sort_values(\"captured_at\")\n",
    "  if sensor != \"Outside\":\n",
    "    dfPressures[\"value\"] /= 100  #divide by 100 to convert from Pascals to mBar\n",
    "\n",
    "  dfLux['captured_at'] = pd.to_datetime(dfLux['captured_at'])\n",
    "  dfLux[\"type\"] = dfLux[\"id\"].str.extract(r'([A-Z]{2,})')\n",
    "  dfLux= dfLux.sort_values(\"captured_at\")\n",
    "\n",
    "  return dfTemps,dfHumids,dfPressures,dfLux\n",
    "# pickData(\"Outside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80DQK-3eXaUs"
   },
   "source": [
    "#### `getData()` - Gets All Data\n",
    "\n",
    "Calls the above function and sets the contents of `data` to the returned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSZ2D_VA3Qbu"
   },
   "outputs": [],
   "source": [
    "# Fetches ALL the data needed to load the graphs\n",
    "# This is only called on the page initial load\n",
    "# Populates the global 'data' variable with all the data\n",
    "def getData():\n",
    "  global data\n",
    "  for sensor in sensors:\n",
    "    data[sensor] = {}\n",
    "    dfTemps,dfHumids,dfPressures,dfLux = pickData(sensor, True)\n",
    "    data[sensor][\"Temperature\"] = dfTemps\n",
    "    data[sensor][\"Humidity\"] = dfHumids\n",
    "    data[sensor][\"Pressure\"] = dfPressures\n",
    "    data[sensor][\"Lux\"] = dfLux\n",
    "# getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAYjwvQDXpyQ"
   },
   "source": [
    "#### `getNewData()` - Gets Most Recent Data\n",
    "\n",
    "Only returns the most recent of each type of reading. Will only add to `data` if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbAPmuKgbDhE"
   },
   "outputs": [],
   "source": [
    "# Runs based on the interval callback\n",
    "# Gets the most recent data for each sensor\n",
    "# If it's newer than what's currently in 'data', add it to 'data'\n",
    "def getNewData():\n",
    "  global data\n",
    "  for sensor in sensors:\n",
    "    dfTemps,dfHumids,dfPressures,dfLux = pickData(sensor,False)\n",
    "    if dfTemps['captured_at'].iloc[0] > data[sensor]['Temperature']['captured_at'].iloc[-1]:\n",
    "      data[sensor]['Temperature'] = data[sensor]['Temperature'].append(dfTemps)\n",
    "      print(\"new Temperature\")\n",
    "    if dfHumids['captured_at'].iloc[0] > data[sensor][\"Humidity\"][\"captured_at\"].iloc[-1]:\n",
    "      data[sensor][\"Humidity\"] = data[sensor][\"Humidity\"].append(dfHumids)\n",
    "      print(\"new Humidity\")\n",
    "    if dfPressures['captured_at'].iloc[0] > data[sensor][\"Pressure\"][\"captured_at\"].iloc[-1]:\n",
    "      data[sensor][\"Pressure\"] = data[sensor][\"Pressure\"].append(dfPressures)\n",
    "      print(\"new Pressure\")\n",
    "    if dfLux['captured_at'].iloc[0] > data[sensor][\"Lux\"][\"captured_at\"].iloc[-1]:\n",
    "      data[sensor][\"Lux\"] = data[sensor][\"Lux\"].append(dfLux)\n",
    "      print(\"new Lux\")\n",
    "  return data\n",
    "# getNewData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eFcKnCihjs6"
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrZTqdjOh2Zz"
   },
   "source": [
    "#### Per-Sensor Plot\n",
    "\n",
    "This plot shows each Reading Type from one sensor and also draws the corresponding reading from Outside.\n",
    "\n",
    "You can zoom on all plots in this demo by clicking and dragging. (not here through, this is just an image)\n",
    "\n",
    "![](https://i.ibb.co/Fmkgdd3/Screen-Shot-2021-09-24-at-4-35-58-PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4R09h1VkL7r"
   },
   "outputs": [],
   "source": [
    "# Four stacked line plots each representing a `Reading_Type` from the selected sensor\n",
    "def drawPlotForSensor(sensor=\"Workshop\"):\n",
    "  print(sensor)\n",
    "  fig = make_subplots(rows=4, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "  # Just add in all the data\n",
    "  # Temperature\n",
    "  fig.add_trace(go.Scatter(x=data[sensor][\"Temperature\"][\"captured_at\"], y=data[sensor][\"Temperature\"][\"value\"], mode=\"lines\", name=\"Temperature\"), row=1, col=1)\n",
    "  fig.add_trace(go.Scatter(x=data[\"Outside\"][\"Temperature\"][\"captured_at\"], y=data[\"Outside\"][\"Temperature\"][\"value\"], mode=\"lines\", name=\"Outside Temperature\"), row=1, col=1)\n",
    "  # Humidity\n",
    "  fig.add_trace(go.Scatter(x=data[sensor][\"Humidity\"][\"captured_at\"], y=data[sensor][\"Humidity\"][\"value\"], mode=\"lines\", name=\"Humidity\"), row=2, col=1)\n",
    "  fig.add_trace(go.Scatter(x=data[\"Outside\"][\"Humidity\"][\"captured_at\"], y=data[\"Outside\"][\"Humidity\"][\"value\"], mode=\"lines\", name=\"Outside Humidity\"), row=2, col=1)\n",
    "  # Pressure\n",
    "  fig.add_trace(go.Scatter(x=data[sensor][\"Pressure\"][\"captured_at\"], y=data[sensor][\"Pressure\"][\"value\"], mode=\"lines\", name=\"Pressure\"), row=3, col=1)\n",
    "  fig.add_trace(go.Scatter(x=data[\"Outside\"][\"Pressure\"][\"captured_at\"], y=data[\"Outside\"][\"Pressure\"][\"value\"], mode=\"lines\", name=\"Outside Pressure\"), row=3, col=1)\n",
    "  # Light\n",
    "  fig.add_trace(go.Scatter(x=data[sensor][\"Lux\"][\"captured_at\"], y=data[sensor][\"Lux\"][\"value\"], mode=\"lines\", name=\"Brightness\"), row=4, col=1)\n",
    "  \n",
    "  # Add Axis Labels to charts\n",
    "  fig.update_layout(\n",
    "      title=sensor + \" Sensor Readings\",\n",
    "      yaxis_title=\"Temperature (C)\",\n",
    "      yaxis2_title=\"Humidity (%)\",\n",
    "      yaxis3_title=\"Pressure (mbar)\",\n",
    "      yaxis4_title=\"Light Intensity (lux)\",\n",
    "      xaxis4_title=\"Datetime\",\n",
    "  )\n",
    "\n",
    "  # Add Background colors to Light Graph\n",
    "  fig.update_layout(\n",
    "      height=800,\n",
    "      shapes=[\n",
    "        dict(type=\"rect\", xref =\"x domain\", yref=\"y4\", x0=0, y0=0.1, x1=1, y1=10, layer=\"below\", fillcolor=\"lightgrey\", line=dict(width=0), ),\n",
    "        dict(type=\"rect\", xref =\"x domain\", yref=\"y4\", x0=0, y0=10, x1=1, y1=100, layer=\"below\", fillcolor=\"lightyellow\", line=dict(width=0)),\n",
    "        dict(type=\"rect\", xref =\"x domain\", yref=\"y4\", x0=0, y0=100, x1=1, y1=1000, layer=\"below\", fillcolor=\"lightblue\", line=dict(width=0)),\n",
    "        dict(type=\"rect\", xref =\"x domain\", yref=\"y4\", x0=0, y0=1000, x1=1, y1=100000, layer=\"below\", fillcolor=\"gold\", line=dict(width=0)),\n",
    "        dict(type=\"line\", xref =\"x domain\", yref=\"y1\", x0=0, y0=20.55, x1=1, y1=20.55, layer=\"below\", fillcolor=\"gold\", line=dict(width=3, dash=\"dashdot\", color=\"steelblue\"), name=\"AC Temp\"),\n",
    "      ])\n",
    "  # Lux is logarithmic\n",
    "  fig.update_yaxes(type=\"log\", row=4, col=1)\n",
    "  fig.update_layout(uirevision='constant')\n",
    "  return fig\n",
    "# drawPlotForSensor(\"Window\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NkiM6VrjE-q"
   },
   "source": [
    "#### Sensor Comparison Plot\n",
    "\n",
    "This plot allows us to compare a given reading type across both sensors and the outdoors. It only shows one reading type at a time, but that will be controlled by a dropdown\n",
    "\n",
    "![](https://i.ibb.co/8Y6xfNN/Screen-Shot-2021-09-24-at-4-42-38-PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EldQaf1wJTjS"
   },
   "outputs": [],
   "source": [
    "# Shows the correspondance between the readings of both sensors and the outdoors\n",
    "def drawOverlapPlot(measurement):\n",
    "  firstOverlap = pd.Timestamp(0, unit='s')\n",
    "  mostRecent = data[\"Window\"][measurement][\"captured_at\"].iloc[-1]\n",
    "  \n",
    "  for sensor in sensors:\n",
    "    firstReading = data[sensor][measurement][\"captured_at\"].iloc[0]\n",
    "    if firstReading > firstOverlap:\n",
    "      firstOverlap = firstReading\n",
    "\n",
    "  fig = go.Figure()\n",
    "\n",
    "  fig.add_trace(go.Scatter(x=data[\"Window\"][measurement][\"captured_at\"], y=data[\"Window\"][measurement][\"value\"], mode=\"lines\", name=\"Window\"))\n",
    "  fig.add_trace(go.Scatter(x=data[\"Workshop\"][measurement][\"captured_at\"], y=data[\"Workshop\"][measurement][\"value\"], mode=\"lines\", name=\"Workshop\"))\n",
    "  if measurement != \"Lux\":\n",
    "    fig.add_trace(go.Scatter(x=data[\"Outside\"][measurement][\"captured_at\"], y=data[\"Outside\"][measurement][\"value\"], mode=\"lines\", name=\"Outside\"))\n",
    "\n",
    "  fig.update_layout(\n",
    "      height=800,\n",
    "      xaxis_range=[firstOverlap, mostRecent]\n",
    "  )\n",
    "  fig.update_layout(uirevision='constant')\n",
    "\n",
    "  if measurement == \"Lux\":\n",
    "    fig.update_layout(\n",
    "      shapes=[\n",
    "        dict(type=\"rect\", xref =\"x domain\", yref=\"y\", x0=0, y0=0.1, x1=1, y1=10, layer=\"below\", fillcolor=\"lightgrey\", line=dict(width=0), ),\n",
    "        dict(type=\"rect\", xref =\"x domain\", yref=\"y\", x0=0, y0=10, x1=1, y1=100, layer=\"below\", fillcolor=\"lightyellow\", line=dict(width=0)),\n",
    "        dict(type=\"rect\", xref =\"x domain\", yref=\"y\", x0=0, y0=100, x1=1, y1=1000, layer=\"below\", fillcolor=\"lightblue\", line=dict(width=0)),\n",
    "        dict(type=\"rect\", xref =\"x domain\", yref=\"y\", x0=0, y0=1000, x1=1, y1=100000, layer=\"below\", fillcolor=\"gold\", line=dict(width=0)),\n",
    "      ])\n",
    "    fig.update_yaxes(type=\"log\")\n",
    "  elif measurement == \"Temperature\":\n",
    "    fig.update_layout(\n",
    "    shapes=[\n",
    "      dict(type=\"line\", xref =\"x domain\", yref=\"y1\", x0=0, y0=20.55, x1=1, y1=20.55, layer=\"below\", fillcolor=\"gold\", line=dict(width=3, dash=\"dashdot\", color=\"steelblue\"), name=\"AC Temp\"),\n",
    "    ])\n",
    "\n",
    "  return fig\n",
    "\n",
    "# drawOverlapPlot(\"Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkg5j2KGjqfj"
   },
   "source": [
    "#### Room View\n",
    "\n",
    "The Room View / Sensor Overview shows the \"Digital Twin\" view of the room and workshop along with the most recent reading from each corresponding sensor.\n",
    "\n",
    "The lighting within the room will change based on what is sensed and in later parts of the tutorial, indicators will show when certain conditions are detected such as the AC being on, or the windows being open.\n",
    "\n",
    "![](https://i.ibb.co/bz94sq3/Screen-Shot-2021-09-24-at-4-45-18-PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHoUjDEon5mN"
   },
   "outputs": [],
   "source": [
    "# CSS styling for the placement of the room images\n",
    "# They need to stack and we'll set their opacity dynamically based on our readings below\n",
    "ROOMIMAGE_STYLE = {\n",
    "    \"width\": \"100%\",\n",
    "    \"maxWidth\": \"850px\",\n",
    "    \"position\": \"absolute\",\n",
    "    \"top\": \"0px\",\n",
    "    \"left\": \"0px\",\n",
    "    \"margin\": \"auto\",\n",
    "}\n",
    "\n",
    "def updateRoom():\n",
    "  # Get the most recent light level\n",
    "  roomLightLevel = data[\"Window\"][\"Lux\"][\"value\"].iloc[-1]\n",
    "    # Set the Lights\n",
    "  if roomLightLevel > 1000:\n",
    "    windowOpacity = math.log(roomLightLevel,10)-2.9\n",
    "    lightsOpacity = 0.0\n",
    "    cloudsOpacity = 0.0\n",
    "  elif roomLightLevel > 10 and roomLightLevel <= 100:\n",
    "    lightsOpacity = 1.0\n",
    "    windowOpacity = 0.0\n",
    "    cloudsOpacity = 0.0\n",
    "  elif roomLightLevel > 100 and roomLightLevel <= 1000:\n",
    "    lightsOpacity = 0.0\n",
    "    windowOpacity = 0.0\n",
    "    cloudsOpacity = math.log(roomLightLevel,10)-1.9\n",
    "  else:\n",
    "    windowOpacity = 0.0\n",
    "    lightsOpacity = 0.0\n",
    "    cloudsOpacity = 0.0\n",
    "\n",
    "  workshopLightLevel = data[\"Workshop\"][\"Lux\"][\"value\"].iloc[-1]\n",
    "    # Set the Lights\n",
    "  if workshopLightLevel > 1000:\n",
    "    workshopWindowOpacity = math.log(workshopLightLevel,10)-2.8\n",
    "    workshopLightsOpacity = 0.0\n",
    "    workshopCloudsOpacity = 0.0\n",
    "  elif workshopLightLevel > 10 and workshopLightLevel <= 100:\n",
    "    workshopLightsOpacity = 1.0\n",
    "    workshopWindowOpacity = 0.0\n",
    "    workshopCloudsOpacity = 0.0\n",
    "  elif workshopLightLevel > 100 and workshopLightLevel <= 1000:\n",
    "    workshopLightsOpacity = 0.0\n",
    "    workshopWindowOpacity = 0.0\n",
    "    workshopCloudsOpacity = math.log(workshopLightLevel,10)-1.8\n",
    "  else:\n",
    "    workshopWindowOpacity = 0.0\n",
    "    workshopLightsOpacity = 0.0\n",
    "    workshopCloudsOpacity = 0.0\n",
    "\n",
    "  # Each `Img` is a \"layer\" in the final room view. Lighting drives the opacity of the different lighting scenarios.\n",
    "  room = [\n",
    "    html.Img(src=\"https://github.com/DanBarkus/IoT-Dashboard/blob/main/images/Both/Room_Dark.png?raw=true\", id=\"room\", className=\"roomImage\", style=ROOMIMAGE_STYLE),\n",
    "    html.Img(src=\"https://github.com/DanBarkus/IoT-Dashboard/blob/main/images/Both/Workshop_Dark.png?raw=true\", id=\"workshop\", className=\"roomImage\", style=ROOMIMAGE_STYLE),\n",
    "    html.Img(src=\"https://github.com/DanBarkus/IoT-Dashboard/blob/main/images/Both/Room_Lights.png?raw=true\", id=\"lights\", className=\"roomImage\", style={**ROOMIMAGE_STYLE, **{\"opacity\":lightsOpacity}}),\n",
    "    html.Img(src=\"https://github.com/DanBarkus/IoT-Dashboard/blob/main/images/Both/Workshop_Lights.png?raw=true\", id=\"workshop-lights\", className=\"roomImage\", style={**ROOMIMAGE_STYLE, **{\"opacity\":workshopLightsOpacity}}),\n",
    "    html.Img(src=\"https://github.com/DanBarkus/IoT-Dashboard/blob/main/images/Both/Room_Cloudy.png?raw=true\", id=\"cloudy\", style={**ROOMIMAGE_STYLE, **{\"opacity\":cloudsOpacity}}),\n",
    "    html.Img(src=\"https://github.com/DanBarkus/IoT-Dashboard/blob/main/images/Both/Workshop_Cloudy.png?raw=true\", id=\"workshop-cloudy\", style={**ROOMIMAGE_STYLE, **{\"opacity\":workshopCloudsOpacity}}),\n",
    "    html.Img(src=\"https://github.com/DanBarkus/IoT-Dashboard/blob/main/images/Both/Room_Sun.png?raw=true\", id=\"sun\", style={**ROOMIMAGE_STYLE, **{\"opacity\":windowOpacity}}),\n",
    "    html.Img(src=\"https://github.com/DanBarkus/IoT-Dashboard/blob/main/images/Both/Workshop_Sun.png?raw=true\", id=\"workshop-sun\", style={**ROOMIMAGE_STYLE, **{\"opacity\":workshopWindowOpacity}})\n",
    "  ]\n",
    "\n",
    "  # These are just the tables that hold the most recent readings for each sensor\n",
    "  windowStats = dbc.Table([\n",
    "    html.Thead([html.Tr([html.Th(\"Reading Type\"), html.Th(\"Reading\")])]),\n",
    "    html.Tr([html.Td(\"Temperature\"), html.Td(str(data[\"Window\"][\"Temperature\"][\"value\"].iloc[-1]) + \"\")]),\n",
    "    html.Tr([html.Td(\"Humidity\"), html.Td(str(data[\"Window\"][\"Humidity\"][\"value\"].iloc[-1]) + \"%\")]),\n",
    "    html.Tr([html.Td(\"Pressure\"), html.Td(str(round(data[\"Window\"][\"Pressure\"][\"value\"].iloc[-1],2)) + \" mbar\")]),\n",
    "    html.Tr([html.Td(\"Light Level\"), html.Td(str(data[\"Window\"][\"Lux\"][\"value\"].iloc[-1]) + \" lux\")]),\n",
    "    html.Tr([html.Td(\"Most Recent\"), html.Td(str(data[\"Window\"][\"Lux\"][\"captured_at\"].iloc[-1]))]),\n",
    "  ],\n",
    "  bordered=True,\n",
    "  size=\"sm\")\n",
    "\n",
    "  workshopStats = dbc.Table([\n",
    "    html.Thead([html.Tr([html.Th(\"Reading Type\"), html.Th(\"Reading\")])]),\n",
    "    html.Tr([html.Td(\"Temperature\"), html.Td(str(data[\"Workshop\"][\"Temperature\"][\"value\"].iloc[-1]) + \"\")]),\n",
    "    html.Tr([html.Td(\"Humidity\"), html.Td(str(data[\"Workshop\"][\"Humidity\"][\"value\"].iloc[-1]) + \"%\")]),\n",
    "    html.Tr([html.Td(\"Pressure\"), html.Td(str(round(data[\"Workshop\"][\"Pressure\"][\"value\"].iloc[-1],2)) + \" mbar\")]),\n",
    "    html.Tr([html.Td(\"Light Level\"), html.Td(str(data[\"Workshop\"][\"Lux\"][\"value\"].iloc[-1]) + \" lux\")]),\n",
    "    html.Tr([html.Td(\"Most Recent\"), html.Td(str(data[\"Workshop\"][\"Lux\"][\"captured_at\"].iloc[-1]))]),\n",
    "  ],\n",
    "  bordered=True,\n",
    "  size=\"sm\")\n",
    "\n",
    "  return room,windowStats,workshopStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHlNWDnqTGUB"
   },
   "source": [
    "### The Rest of the Page\n",
    "\n",
    "Now that the charts are taken care of, it's time to build the actual page(s) and thier components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-6ORjGTTKut"
   },
   "source": [
    "#### Sidebar\n",
    "\n",
    "The sidebar will serve as the navigation between our pages and just hold some additional information about the Site as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OY-UKbRwHNMK"
   },
   "outputs": [],
   "source": [
    "SIDEBAR_STYLE = {\n",
    "    \"position\": \"fixed\",\n",
    "    \"top\": 0,\n",
    "    \"left\": 0,\n",
    "    \"bottom\": 0,\n",
    "    \"width\": \"16rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "    \"backgroundColor\": \"#424242\"\n",
    "}\n",
    "TG_LOGO = \"https://res.cloudinary.com/crunchbase-production/image/upload/c_lpad,h_170,w_170,f_auto,b_white,q_auto:eco,dpr_1/vootpjtmcyx0gt79zl6r\"\n",
    "\n",
    "sidebar = html.Div(\n",
    "    [\n",
    "        # A brief description \n",
    "\n",
    "        html.Center(html.H1(\n",
    "            \"IoT Digital Twin for interior Micro-Climates\", className=\"lead\", style={'color':\"#FF6D01\"}\n",
    "        )),\n",
    "        html.Br(), \n",
    "     \n",
    "        # The navbar itself\n",
    "        dbc.Nav(\n",
    "            [\n",
    "                dbc.NavLink(\"Per-sensor Readings\", href=\"/\", active=\"exact\", style={'color':'white'}),\n",
    "                dbc.NavLink(\"Sensor Comparisons\", href=\"/comparison\", active=\"exact\", style={'color':'white'}),\n",
    "            ],\n",
    "            vertical=True,\n",
    "            pills=True,\n",
    "        ),\n",
    "     \n",
    "        html.Br(), \n",
    "        html.Br(), \n",
    "     \n",
    "        # The TigerGraph logo as well as a link to TG Cloud\n",
    "     \n",
    "        html.Center(dbc.Row(dbc.Col(html.Img(src=TG_LOGO, height=\"150px\", style={\"marginBottom\": \"15px\"})))),\n",
    "        html.Center(html.B(html.A(\"TigerGraph Cloud\", href=\"https://www.tigergraph.com/cloud/\", target=\"_blank\", style={'color':'white'}))),\n",
    "\n",
    "    ],\n",
    "    style=SIDEBAR_STYLE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyaHY-6TTNpQ"
   },
   "source": [
    "#### Chart Holders and Dropdowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BWwdru1PRkB"
   },
   "source": [
    "General structure for the room view. \n",
    "\n",
    "Stats - Room - Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyXEYAAl-Mxj"
   },
   "outputs": [],
   "source": [
    "roomView = dbc.Row([\n",
    "  dbc.Col([\n",
    "    html.H3([\"Workshop\"]),\n",
    "    html.Div(\n",
    "        id=\"workshop-stats\",\n",
    "        style={\"display\":\"flex\", \"flexDirection\":\"column\"})\n",
    "  ], width=3),\n",
    "  # Holds the room image\n",
    "  dbc.Col(\n",
    "      id='room-container',\n",
    "  style={\"position\": \"relative\", \"width\": \"800px\", \"height\": \"450px\", \"flex\": \"none\"},\n",
    "  width=6),\n",
    "  # Holds the current Stats\n",
    "  dbc.Col([\n",
    "    html.H3([\"Window\"]),\n",
    "    html.Div(\n",
    "        id=\"window-stats\",\n",
    "        style={\"display\":\"flex\", \"flexDirection\":\"column\"})\n",
    "  ], width=3)\n",
    "  ],style={\"display\":\"flex\", \"alignItems\": \"center\", \"justifyContent\":\"space-around\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqB-k4f4AvlM"
   },
   "outputs": [],
   "source": [
    "# Holds the per sensor graph\n",
    "sensorsView = dbc.Row([\n",
    "    dbc.Col([\n",
    "      html.H3(\"Window\", id=\"sensor-display\"),\n",
    "      dbc.DropdownMenu(\n",
    "          [dbc.DropdownMenuItem(x, id=x) for x in sensors if x != \"Outside\"],\n",
    "          id='dropdown-location',\n",
    "          label=\"Select Sensor\",\n",
    "          bs_size='lg'\n",
    "      ),\n",
    "      dcc.Loading(children=[\n",
    "          dcc.Graph(id=\"graph\"),\n",
    "      ],\n",
    "      type=\"graph\",\n",
    "      )\n",
    "    ],\n",
    "    width=12\n",
    "    ),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzFXd1eECB83"
   },
   "outputs": [],
   "source": [
    "# Holds the comparison Graph\n",
    "comparisonView = html.Div([\n",
    "    html.H3(\"Temperature\", id=\"type-display\"),\n",
    "    dbc.DropdownMenu(\n",
    "        [dbc.DropdownMenuItem(x, id=x) for x in readingTypes],\n",
    "        id='dropdown-type', \n",
    "        label='Select Reading Type'\n",
    "    ),\n",
    "    dcc.Loading(children=[\n",
    "        dcc.Graph(id=\"comparison-graph\"),\n",
    "    ],\n",
    "    type=\"graph\",\n",
    "    )\n",
    "  ],\n",
    "  style={\"alignSelf\":\"flex-end\", \"width\":\"100%\"}\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTWOQjYATQs9"
   },
   "source": [
    "### The Dash App Itself\n",
    "\n",
    "This is where everything comes together. All of our components are in their place and the only thing left to do is declare the Dash app itself and its callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "M3PavBCezpHd",
    "outputId": "68a04c71-1b80-486d-dd28-0ecdadd40711"
   },
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.DARKLY], suppress_callback_exceptions=True)\n",
    "\n",
    "getData()\n",
    "\n",
    "app.layout = html.Div([\n",
    "    # Data store\n",
    "    dcc.Store(id='graph-data'),\n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=120*1000, # in milliseconds\n",
    "        n_intervals=0\n",
    "    ),\n",
    "    dcc.Location(id=\"url\"),\n",
    "    # Main wrapper div\n",
    "    dbc.Container([\n",
    "        sidebar,\n",
    "        roomView,\n",
    "        html.Div([],id=\"content-holder\"),\n",
    "    ],\n",
    "    fluid=True,\n",
    "    style={\"paddingLeft\":\"17rem\"}),\n",
    "])   \n",
    "app.scripts.config.serve_locally = False\n",
    "\n",
    "# -----------------------------\n",
    "# ----- Here be Callbacks -----\n",
    "# -----------------------------\n",
    "\n",
    "# Navigation callback\n",
    "@app.callback(Output(\"content-holder\", \"children\"), \n",
    "              [Input(\"url\", \"pathname\")])\n",
    "def render_page_content(pathname):\n",
    "    if pathname == \"/\":\n",
    "      return sensorsView \n",
    "    elif pathname == \"/comparison\":\n",
    "      return comparisonView\n",
    "    elif pathname == \"/page-2\":\n",
    "      return personContent \n",
    "    # If the user tries to reach a different page, return an error!\n",
    "    return dbc.Jumbotron([\n",
    "      html.H1(\"404: Not found\", className=\"text-danger\"),\n",
    "      html.Hr(),\n",
    "      html.P(\"Uh oh! Unfortunately, the pathname {pathname} was unable to be recognised...\"),\n",
    "    ])\n",
    "\n",
    "# Sensor select callback (also triggers on data update)\n",
    "@app.callback(\n",
    "    [Output(\"graph\", \"figure\"),\n",
    "     Output(\"sensor-display\", \"children\")],\n",
    "    [Input(\"Window\", \"n_clicks\"),\n",
    "     Input(\"Workshop\", \"n_clicks\"),\n",
    "     Input('graph-data', 'data')])\n",
    "def update_graph_sensor(n1,n2,d):\n",
    "    global currentSensor\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "      btn_id = \"Window\"\n",
    "    else:\n",
    "      btn_id = ctx.triggered[0][\"prop_id\"].split(\".\")[0]\n",
    "      if btn_id == \"graph-data\":\n",
    "        btn_id = currentSensor\n",
    "    currentSensor = btn_id\n",
    "    fig = drawPlotForSensor(btn_id)\n",
    "    return fig, btn_id\n",
    "\n",
    "# Reading select callback (also triggers on data update)\n",
    "@app.callback(\n",
    "    [Output(\"comparison-graph\", \"figure\"),\n",
    "     Output(\"type-display\", \"children\")],\n",
    "    [Input(\"Temperature\", \"n_clicks\"),\n",
    "     Input(\"Humidity\", \"n_clicks\"),\n",
    "     Input(\"Pressure\", \"n_clicks\"),\n",
    "     Input(\"Lux\", \"n_clicks\"),\n",
    "     Input('graph-data', 'data')\n",
    "     ])\n",
    "def update_graph_comparison(n1,n2,n3,n4,d):\n",
    "    global currentType\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "      btn_id = \"Temperature\"\n",
    "    else:\n",
    "      btn_id = ctx.triggered[0][\"prop_id\"].split(\".\")[0]\n",
    "      if btn_id == \"graph-data\":\n",
    "        btn_id = currentType\n",
    "    currentType = btn_id\n",
    "    fig = drawOverlapPlot(btn_id)\n",
    "    return fig, btn_id\n",
    "\n",
    "# Room update on data update\n",
    "@app.callback(\n",
    "    [Output('room-container', 'children'),\n",
    "     Output('window-stats', 'children'),\n",
    "     Output('workshop-stats', 'children')],\n",
    "     Input('graph-data','data'))\n",
    "def update_room(d):\n",
    "    room,windowStats,workshopStats = updateRoom()\n",
    "    return room,windowStats,workshopStats\n",
    "\n",
    "# Interval callback to check for new data every minute\n",
    "@app.callback(\n",
    "    Output('graph-data', 'data'), \n",
    "    Input('interval-component', 'n_intervals'),\n",
    "    State('graph-data', 'data'), prevent_initial_call=True)\n",
    "def update_data(n_intervals, dat):\n",
    "    getNewData()\n",
    "    return {}\n",
    "\n",
    "\n",
    "app.run_server(mode=\"external\", port=5051, debug=True, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "oemQcCy6I3hM",
    "outputId": "f3648c44-3108-42e6-ea3c-2a263ac2c05b"
   },
   "outputs": [],
   "source": [
    "conn.gsql('''\n",
    "CREATE SCHEMA_CHANGE JOB add_next_reading FOR GRAPH IoTDashboard { \n",
    "  ADD DIRECTED EDGE next_reading(FROM Reading, TO Reading, seconds_between FLOAT, delta_value FLOAT) WITH REVERSE_EDGE=\"reverse_next_reading\";\n",
    "}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XzTKxAzKJBnM",
    "outputId": "c743b33f-823e-47a7-8c3b-3344a2469ebb"
   },
   "outputs": [],
   "source": [
    "conn.gsql('''\n",
    "RUN SCHEMA_CHANGE JOB add_next_reading\n",
    "DROP JOB add_next_reading\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riLTZx1f67Cz"
   },
   "outputs": [],
   "source": [
    "for sensor in sensors:\n",
    "  for typ in readingTypes:\n",
    "    if sensor == 'Outside' and typ == 'LUX':\n",
    "      typ = \"CLOUD\"\n",
    "    conn.runInstalledQuery('addNextEdge', {'inDevice': sensor, 'inReading':typ.upper()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pd2vd9sdUzLP"
   },
   "outputs": [],
   "source": [
    "for sensor in sensors:\n",
    "  res = conn.runInstalledQuery(\"exportData\", params={\"inDevice\": sensor})\n",
    "  df = conn.vertexSetToDataFrame(res[0][\"deviceReadings\"])\n",
    "  df = df.sort_values(\"captured_at\")\n",
    "  df = df.drop(columns=['v_id', 'id'])\n",
    "  df = df.reindex(columns=['@device', '@rdgType', 'value', 'type', 'captured_at'])\n",
    "  df.to_csv(sensor + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4mw0316S0Rk"
   },
   "source": [
    "Generate Edges between readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "UbquTVQNTHQY",
    "outputId": "3c86ec1e-72a2-49a2-ca64-4dcda7d6606b"
   },
   "outputs": [],
   "source": [
    "conn.gsql(\n",
    "    '''\n",
    "    USE GRAPH IoTDashboard\n",
    "    CREATE QUERY addNextEdge(VERTEX<Device> inDevice, VERTEX<Reading_Type> inReading) FOR GRAPH IoTDashboard SYNTAX v2{ \n",
    "      TYPEDEF TUPLE<DATETIME date, VERTEX<Reading> reading> readingOrder;\n",
    "      VERTEX<Reading> prevReading;\n",
    "      VERTEX<Reading> currentReading;\n",
    "      FLOAT timeDelta;\n",
    "      FLOAT valueDelta;\n",
    "      SetAccum<VERTEX<Reading>> @@readings;\n",
    "      HeapAccum<readingOrder>(10, date ASC) @@allReadings;\n",
    "      device = {inDevice};\n",
    "      rdgType = {inReading};\n",
    "      readings = {Reading.*};\n",
    "      \n",
    "      @@allReadings.resize(readings.size());\n",
    "\n",
    "      readings = SELECT r FROM device - () - Reading:r - () - rdgType\n",
    "        WHERE\n",
    "          r.outdegree(\"next_reading\") == 0\n",
    "        ACCUM\n",
    "          @@readings += r\n",
    "        POST-ACCUM\n",
    "          @@allReadings += readingOrder(r.captured_at, r);\n",
    "      \n",
    "      @@allReadings.resize(readings.size());\n",
    "      \n",
    "      PRINT @@allReadings;\n",
    "      \n",
    "      FOREACH reading in @@readings DO\n",
    "        IF @@allReadings.size() > 1 THEN\n",
    "          prevReading = @@allReadings.pop().reading;\n",
    "          currentReading = @@allReadings.top().reading;\n",
    "          timeDelta = datetime_to_epoch(currentReading.captured_at) - datetime_to_epoch(prevReading.captured_at);\n",
    "          valueDelta = currentReading.value - prevReading.value;\n",
    "          INSERT INTO next_reading (FROM, TO, seconds_between, delta_value)VALUES (prevReading.id, currentReading.id, timeDelta, valueDelta);\n",
    "        ELSE\n",
    "          BREAK;\n",
    "        END;\n",
    "      END;\n",
    "    }\n",
    "    '''\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IoT Graph",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
